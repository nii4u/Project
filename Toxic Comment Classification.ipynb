{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/thompson/Downloads/train.csv')\n",
    "test = pd.read_csv('/home/thompson/Downloads/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  Yo bitch Ja Rule is more succesful then you'll...\n",
       "1  0000247867823ef7  == From RfC == \\n\\n The title is fine as it is...\n",
       "2  00013b17ad220c46  \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lap...\n",
       "3  00017563c3f7919a  :If you have a look back at the source, the in...\n",
       "4  00017695ad8997eb          I don't anonymously edit articles at all."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train['comment_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(394.0732213246768, 590.7202819048923, 5000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train\n",
    "lens = train.comment_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(364.8751207855632, 592.4920987303017, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test\n",
    "lens = test.comment_text.str.len()\n",
    "lens.mean(), lens.std(), lens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb3c9c48828>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>none</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.898321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "      <td>0.302226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate           none  \n",
       "count  159571.000000  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805       0.898321  \n",
       "std         0.216627       0.093420       0.302226  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "25%         0.000000       0.000000       1.000000  \n",
       "50%         0.000000       0.000000       1.000000  \n",
       "75%         0.000000       0.000000       1.000000  \n",
       "max         1.000000       1.000000       1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "train['none'] = 1-train[label_cols].max(axis=1) ## each column may have the value of one ( Labled ) . 1- calc the max # if has no lable max = 0 then col = 1 -0 = 0\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 153164)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## deal with nulls \n",
    "COMMENT = 'comment_text'\n",
    "train[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "test[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(s): \n",
    "    return re_tok.sub(r' \\1 ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', '?', 'They', 'weren', \"'\", 't', 'vandalisms', ',', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', '.', 'And', 'please', 'don', \"'\", 't', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'I', \"'\", 'm', 'retired', 'now', '.', '89', '.', '205', '.', '38', '.', '27', 'D', \"'\", 'aww', '!', 'He', 'matches', 'this', 'background', 'colour', 'I', \"'\", 'm', 'seemingly', 'stuck', 'with', '.', 'Thanks', '.', '(', 'talk', ')', '21', ':', '51', ',', 'January', '11', ',', '2016', '(', 'UTC', ')', 'Hey', 'man', ',', 'I', \"'\", 'm', 'really', 'not']\n",
      "13610355 234714\n"
     ]
    }
   ],
   "source": [
    "# vocab size \n",
    "words = []\n",
    "for t in text:\n",
    "    words.extend(tokenize(t))\n",
    "print(words[:100])\n",
    "vocab = list(set(words))\n",
    "print(len(words), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['comment_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted ?  They weren ' t vandalisms ,  just closure on some GAs after I voted at New York Dolls FAC .  And please don ' t remove the template from the talk page since I ' m retired now . 89 . 205 . 38 . 27\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(train['comment_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_word_embedding(vtrain_data, vtest_data):\n",
    "    # switch data back to text \n",
    "    train_labels = vtrain_data[label_cols]\n",
    "    txt_train_data = [clean(txt) for txt in train['comment_text']]\n",
    "    txt_test_data = [clean(txt) for txt in test['comment_text']]\n",
    "    \n",
    "    # integer encode the documents\n",
    "    vocab_size = 10000\n",
    "    encoded_txt_train_data = [keras.preprocessing.text.one_hot(d, vocab_size) for d in txt_train_data]\n",
    "    encoded_txt_test_data = [keras.preprocessing.text.one_hot(d, vocab_size) for d in txt_test_data]\n",
    "    #print(encoded_txt_train_data)\n",
    "\n",
    "    ptxt_train_data = keras.preprocessing.sequence.pad_sequences(encoded_txt_train_data,\n",
    "                                                            padding='post',\n",
    "                                                            maxlen=5000)\n",
    "\n",
    "    ptxt_test_data = keras.preprocessing.sequence.pad_sequences(encoded_txt_test_data,\n",
    "                                                           padding='post',\n",
    "                                                           maxlen=5000)\n",
    "    x_val = ptxt_train_data[:100000] \n",
    "    partial_x_train = ptxt_train_data[100000:]\n",
    "\n",
    "    y_val = train_labels[:100000]\n",
    "    partial_y_train = train_labels[100000:]\n",
    "    return (x_val,partial_x_train,y_val,partial_y_train,ptxt_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def full_one_hot_word_embedding(vtrain_data,vtest_data):\n",
    "    # switch data back to text \n",
    "    train_labels = vtrain_data[label_cols]\n",
    "    txt_train_data = [clean(txt) for txt in train['comment_text']]\n",
    "    txt_test_data = [clean(txt) for txt in test['comment_text']]\n",
    "    \n",
    "    # integer encode the documents\n",
    "    vocab_size = 10000\n",
    "    encoded_txt_train_data = [keras.preprocessing.text.one_hot(d, vocab_size) for d in txt_train_data]\n",
    "    encoded_txt_test_data = [keras.preprocessing.text.one_hot(d, vocab_size) for d in txt_test_data]\n",
    "    #print(encoded_txt_train_data)\n",
    "\n",
    "    ptxt_train_data = keras.preprocessing.sequence.pad_sequences(encoded_txt_train_data,\n",
    "                                                            padding='post',\n",
    "                                                            maxlen=5000)\n",
    "\n",
    "    ptxt_test_data = keras.preprocessing.sequence.pad_sequences(encoded_txt_test_data,\n",
    "                                                           padding='post',\n",
    "                                                           maxlen=5000)\n",
    "    partial_x_train = ptxt_train_data\n",
    "    partial_y_train = train_labels\n",
    "    return (partial_x_train,partial_y_train,ptxt_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_with_emb_acc(vtrain_data,vtest_data,vocab_size = 10000):\n",
    "#     model1 = keras.Sequential()\n",
    "#     model1.add(keras.layers.Embedding(vocab_size, 16))\n",
    "#     model1.add(keras.layers.GlobalAveragePooling1D())\n",
    "#     model1.add(keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "#     model1.add(keras.layers.Dense(6, activation=tf.nn.sigmoid))\n",
    "#     model1.compile(optimizer='adam',\n",
    "#               loss='binary_crossentropy',\n",
    "#               metrics=['acc'])\n",
    "#     x_val,partial_x_train,y_val,partial_y_train,test_data = one_hot_word_embedding(vtrain_data,vtest_data)\n",
    "#     earlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "#     history = model1.fit(x_val,\n",
    "#                      y_val,\n",
    "#                      epochs=20,\n",
    "#                      callbacks=[earlystopper],\n",
    "#                      batch_size=512,\n",
    "#                      validation_data=(x_val, y_val),\n",
    "#                      verbose=1)\n",
    "# #   results1 = model1.evaluate(x_val, y_val)\n",
    "#     return (model1,test_data,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model_with_emb_acc(vtrain_data,vtest_data,vocab_size = 10000):\n",
    "    model1 = keras.Sequential()\n",
    "    model1.add(keras.layers.Embedding(vocab_size, 16))\n",
    "    model1.add(keras.layers.GlobalAveragePooling1D())\n",
    "    model1.add(keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "    model1.add(keras.layers.Dense(6, activation=tf.nn.sigmoid))\n",
    "    model1.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    partial_x_train,partial_y_train,test_data = full_one_hot_word_embedding(vtrain_data,vtest_data)\n",
    "    earlystopper = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "    history = model1.fit(partial_x_train,\n",
    "                     partial_y_train,\n",
    "                     epochs=20,\n",
    "                     callbacks=[earlystopper],\n",
    "                     batch_size=1024,\n",
    "                     verbose=1)\n",
    "#   results1 = model1.evaluate(x_val, y_val)\n",
    "    return (model1, test_data, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9603WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 82s 515us/sample - loss: 0.2596 - acc: 0.9603\n",
      "Epoch 2/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9633WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 81s 508us/sample - loss: 0.1410 - acc: 0.9633\n",
      "Epoch 3/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9633WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 81s 507us/sample - loss: 0.1407 - acc: 0.9633\n",
      "Epoch 4/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9633WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 81s 509us/sample - loss: 0.1404 - acc: 0.9633\n",
      "Epoch 5/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9633WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 81s 511us/sample - loss: 0.1401 - acc: 0.9633\n",
      "Epoch 6/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9633WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 82s 514us/sample - loss: 0.1396 - acc: 0.9633\n",
      "Epoch 7/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9634WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 81s 510us/sample - loss: 0.1389 - acc: 0.9634\n",
      "Epoch 8/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9634WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 84s 524us/sample - loss: 0.1371 - acc: 0.9634\n",
      "Epoch 9/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9635WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 84s 528us/sample - loss: 0.1340 - acc: 0.9635\n",
      "Epoch 10/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9636WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 523us/sample - loss: 0.1302 - acc: 0.9636\n",
      "Epoch 11/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9637WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 84s 526us/sample - loss: 0.1264 - acc: 0.9637\n",
      "Epoch 12/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9638WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 88s 553us/sample - loss: 0.1221 - acc: 0.9638\n",
      "Epoch 13/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9639WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 520us/sample - loss: 0.1171 - acc: 0.9639\n",
      "Epoch 14/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9643WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 518us/sample - loss: 0.1119 - acc: 0.9643\n",
      "Epoch 15/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9649WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 518us/sample - loss: 0.1063 - acc: 0.9650\n",
      "Epoch 16/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9658WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 84s 527us/sample - loss: 0.1017 - acc: 0.9658\n",
      "Epoch 17/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9666WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 84s 527us/sample - loss: 0.0980 - acc: 0.9666\n",
      "Epoch 18/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9674WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 520us/sample - loss: 0.0948 - acc: 0.9674\n",
      "Epoch 19/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9681WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 520us/sample - loss: 0.0920 - acc: 0.9681\n",
      "Epoch 20/20\n",
      "158720/159571 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9688WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\n",
      "159571/159571 [==============================] - 83s 522us/sample - loss: 0.0898 - acc: 0.9688\n"
     ]
    }
   ],
   "source": [
    "model1, test_data, his1 = full_model_with_emb_acc(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model1.predict(test_data, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.7724909e-01, 2.2120598e-01, 7.8460228e-01, 4.3894947e-02,\n",
       "        7.8896004e-01, 1.4230275e-01],\n",
       "       [5.2026182e-02, 5.5297911e-03, 2.4910301e-02, 2.6593804e-03,\n",
       "        2.2120684e-02, 6.3656569e-03],\n",
       "       [7.9448223e-02, 7.5793564e-03, 3.7755847e-02, 3.3310652e-03,\n",
       "        3.3986747e-02, 8.2931519e-03],\n",
       "       ...,\n",
       "       [8.0744326e-03, 1.1092722e-03, 3.8770139e-03, 7.6392293e-04,\n",
       "        3.0883253e-03, 1.6106963e-03],\n",
       "       [1.2584597e-02, 1.9344389e-03, 6.3088238e-03, 1.2625456e-03,\n",
       "        5.3074360e-03, 2.6450753e-03],\n",
       "       [2.2500393e-01, 1.7848134e-02, 1.1071947e-01, 6.2272251e-03,\n",
       "        1.0336909e-01, 1.7065704e-02]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
